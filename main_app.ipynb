{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milagros.cordinez/Library/Caches/pypoetry/virtualenvs/image-lyrics-fA5n5Nhs-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "def generate_caption(image_name):\n",
    "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "\n",
    "    # Path to the image in the images directory\n",
    "    img_path = os.path.join('docs/images', image_name)\n",
    "    raw_image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    # conditional image captioning\n",
    "    text = \"a photography of\"\n",
    "    inputs = processor(raw_image, text, return_tensors=\"pt\")\n",
    "\n",
    "    out = model.generate(**inputs)\n",
    "    print(processor.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "    # unconditional image captioning\n",
    "    inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "\n",
    "    out = model.generate(**inputs)\n",
    "    return processor.decode(out[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ------------- Retrieval-Augmented Generation  ------------- #\n",
    "\n",
    "def get_docs():\n",
    "    \"\"\"\n",
    "    Loads each file into one document, like knowledge base\n",
    "    :return: docs\n",
    "    \"\"\"\n",
    "\n",
    "    loader = DirectoryLoader(\"docs/lyrics\", \"*.txt\", loader_cls=TextLoader)  # Reads custom data from local files\n",
    "\n",
    "    docs = loader.load()\n",
    "    return docs\n",
    "\n",
    "def split_text(docs):\n",
    "    \"\"\"\n",
    "    Get chunks from docs. Our loaded doc may be too long for most models, and even if it fits is can struggle to find relevant context. So we generate chunks\n",
    "    :param docs: docs to be split\n",
    "    :return: chunks\n",
    "    \"\"\"\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter( # recommended splitter for generic text\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100,\n",
    "        add_start_index=True\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def get_data_store(chunks):\n",
    "    \"\"\"\n",
    "    Store chunks into a db. ChromaDB uses vector embeddings as the key, creates a new DB from the documents\n",
    "    :param docs:\n",
    "    :param chunks:\n",
    "    :return: database\n",
    "    \"\"\"\n",
    "    embeddings = HuggingFaceEmbeddings( #  embedding=OpenAIEmbeddings() rate limit\n",
    "        model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "        model_kwargs={'device': 'cpu'} # TODO gpu\n",
    "    )\n",
    "\n",
    "    db = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bx/hkzp8fd13rg05rzvs37tpvd80000gp/T/ipykernel_53494/2354732922.py:42: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings( #  embedding=OpenAIEmbeddings() rate limit\n",
      "/Users/milagros.cordinez/Library/Caches/pypoetry/virtualenvs/image-lyrics-fA5n5Nhs-py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Batch size 194361 exceeds maximum batch size 41666",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m docs \u001b[38;5;241m=\u001b[39m get_docs()           \u001b[38;5;66;03m# Load custom files\u001b[39;00m\n\u001b[1;32m      6\u001b[0m chunks \u001b[38;5;241m=\u001b[39m split_text(docs)   \u001b[38;5;66;03m# Split into chunks\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Generate vectorstore\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m, in \u001b[0;36mget_data_store\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03mStore chunks into a db. ChromaDB uses vector embeddings as the key, creates a new DB from the documents\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m:param docs:\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m:param chunks:\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m:return: database\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings( \u001b[38;5;66;03m#  embedding=OpenAIEmbeddings() rate limit\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     44\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m} \u001b[38;5;66;03m# TODO gpu\u001b[39;00m\n\u001b[1;32m     45\u001b[0m )\n\u001b[0;32m---> 47\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m db\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/image-lyrics-fA5n5Nhs-py3.12/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:878\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    876\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    877\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/image-lyrics-fA5n5Nhs-py3.12/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:842\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    836\u001b[0m         chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(\n\u001b[1;32m    837\u001b[0m             texts\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[1;32m    838\u001b[0m             metadatas\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    839\u001b[0m             ids\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    840\u001b[0m         )\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 842\u001b[0m     \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/image-lyrics-fA5n5Nhs-py3.12/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:313\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg)\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 313\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m empty_ids:\n\u001b[1;32m    315\u001b[0m     texts_without_metadatas \u001b[38;5;241m=\u001b[39m [texts[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m empty_ids]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/image-lyrics-fA5n5Nhs-py3.12/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:299\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m ids_with_metadata \u001b[38;5;241m=\u001b[39m [ids[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m non_empty_ids]\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids_with_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadata value to be\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/image-lyrics-fA5n5Nhs-py3.12/lib/python3.12/site-packages/chromadb/api/models/Collection.py:302\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    None\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    292\u001b[0m (\n\u001b[1;32m    293\u001b[0m     ids,\n\u001b[1;32m    294\u001b[0m     embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m     ids, embeddings, metadatas, documents, images, uris\n\u001b[1;32m    300\u001b[0m )\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/image-lyrics-fA5n5Nhs-py3.12/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py:146\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/image-lyrics-fA5n5Nhs-py3.12/lib/python3.12/site-packages/chromadb/api/segment.py:430\u001b[0m, in \u001b[0;36mSegmentAPI._upsert\u001b[0;34m(self, collection_id, ids, embeddings, metadatas, documents, uris)\u001b[0m\n\u001b[1;32m    428\u001b[0m coll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_collection(collection_id)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mhint_use_collection(collection_id, t\u001b[38;5;241m.\u001b[39mOperation\u001b[38;5;241m.\u001b[39mUPSERT)\n\u001b[0;32m--> 430\u001b[0m \u001b[43mvalidate_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_batch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_max_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m records_to_submit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    435\u001b[0m     _records(\n\u001b[1;32m    436\u001b[0m         t\u001b[38;5;241m.\u001b[39mOperation\u001b[38;5;241m.\u001b[39mUPSERT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    443\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_embedding_record_set(coll, records_to_submit)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/image-lyrics-fA5n5Nhs-py3.12/lib/python3.12/site-packages/chromadb/api/types.py:571\u001b[0m, in \u001b[0;36mvalidate_batch\u001b[0;34m(batch, limits)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_batch\u001b[39m(\n\u001b[1;32m    561\u001b[0m     batch: Tuple[\n\u001b[1;32m    562\u001b[0m         IDs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m     limits: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    569\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m limits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m exceeds maximum batch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlimits[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Batch size 194361 exceeds maximum batch size 41666"
     ]
    }
   ],
   "source": [
    "import os, sys, warnings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "docs = get_docs()           # Load custom files\n",
    "chunks = split_text(docs)   # Split into chunks\n",
    "db = get_data_store(chunks) # Generate vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def generate_response(db, prompt):\n",
    "    \"\"\"\n",
    "    Generate a response with a LLM based on previous custom context\n",
    "    :return: chatbot response\n",
    "    \"\"\"\n",
    "\n",
    "    hf_llm = HuggingFaceHub(\n",
    "        repo_id=\"HuggingFaceH4/zephyr-7b-beta\",  # Model id\n",
    "        task=\"text-generation\",                  # Specific task the model is intended to perform\n",
    "        model_kwargs={\n",
    "            \"max_new_tokens\": 512,               # The maximum number of tokens to generate in the response.  Limits the length of the generated text to ensure responses are concise or fit within certain constraints.\n",
    "            \"top_k\": 30,                         # Limits the sampling pool to the top k tokens, increasing focus on more likely tokens\n",
    "            \"temperature\": 0.3,                  # Controls the randomness of predictions, with lower values making the output more deterministic. : Produces more focused and less random text by making the model more confident in its choices.\n",
    "            \"repetition_penalty\": 1.2,           # Penalizes repeated tokens to avoid repetitive output.  Discourages the model from repeating the same token sequences, resulting in more varied and natural text.\n",
    "        },\n",
    "    )\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type( # Generate chat model based on previous llm\n",
    "        llm=hf_llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2}),\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    response = chain.run(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_response(response):\n",
    "    answer_start = response.find(\"Helpful Answer: \")\n",
    "    if answer_start != -1:\n",
    "        answer = response[answer_start + len(\"Helpful Answer: \"):].strip()\n",
    "    else:\n",
    "        answer = response.strip()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hola! Por favor inserte el nombre de la imagen que quieras usar para escribir una canción. Las imágenes se encuentran dentro de la carpeta /docs/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milagros.cordinez/Library/Caches/pypoetry/virtualenvs/image-lyrics-fA5n5Nhs-py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Users/milagros.cordinez/Library/Caches/pypoetry/virtualenvs/image-lyrics-fA5n5Nhs-py3.12/lib/python3.12/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a photography of a lake with a mountain in the background\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bx/hkzp8fd13rg05rzvs37tpvd80000gp/T/ipykernel_50568/811527098.py:10: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  hf_llm = HuggingFaceHub(\n",
      "/var/folders/bx/hkzp8fd13rg05rzvs37tpvd80000gp/T/ipykernel_50568/811527098.py:28: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Mountains come out of the sky and they stand there\n",
      "One mile over we'll be there and we'll see you\n",
      "Ten true summers we'll be there and laughing tooTwenty four before my love you'll see\n",
      "I'll be there with you\n",
      "[Outro with Vocalizations]\n",
      "\n",
      "[Verse 1:]\n",
      "Ah ah ah ah\n",
      "If you need me, call me\n",
      "No matter where you are\n",
      "No matter how far\n",
      "Just call my name\n",
      "I'll be there in a hurry\n",
      "On that you can depend and never worry\n",
      "You see, my love is alive\n",
      "It's like a seed that only needs the thought of you to grow\n",
      "So if you feel the need for company\n",
      "Please, my darling, let it be me\n",
      "I may not be able to express\n",
      "The depth of the love I feel for you\n",
      "But a writer put it very nicely\n",
      "When he was away from the one he loved\n",
      "He sat down and wrote these words\n",
      "[Bridge:]\n",
      "No wind, (no wind) no rain, (no rain)\n",
      "Nor winter's coldCan stop me, babe (oh, babe) baby (baby)\n",
      "If you're my goal\n",
      "No wind, no rain\n",
      "Can stop\n",
      "If you want to go\n",
      "[Verse 2:]\n",
      "I know, I know you must follow the sun\n",
      "Wherever it leads\n",
      "But remember\n",
      "If you should fall short of your desires\n",
      "Remember life holds for you one guarantee\n",
      "You'll always have me\n",
      "And if you should miss my love\n",
      "One of these old days\n",
      "If you should ever miss the arms\n",
      "That used to hold you so close, or the lips\n",
      "That used to touch yours so tenderly\n",
      "Just remember what I told you\n",
      "The day I set you free\n",
      "Ain't no mountain high enough, aah\n",
      "Ain't no valley low enough (say it again)\n",
      "Ain't no river wide enough\n",
      "To keep me from you\n",
      "Ain't no mountain high enough\n",
      "Ain't no valley low enough (say it again)\n",
      "Ain't no river wide enough\n",
      "To keep me from you\n",
      "Ain't no mountain high enough\n",
      "Nothing can keep me\n",
      "To keep me from you\n",
      "Ain't no mountain high enough\n",
      "Ain't no valley low enough (one more time)\n",
      "Ain't no river wide enough (say it again)\n",
      "To keep me from you\n",
      "Ain't no mountain high enough\n",
      "Nothing can keep me\n",
      "To keep me from you\n",
      "Nothing in this world\n",
      "\n",
      "Question: Write a song lyrics about \"arafed mountain in the distance with a lake and red leaves\" having intro, verse 1, chorus 1, verse 2, chorus 2, bridge, chorus 3, outro.\n",
      "Helpful Answer: Intro:\n",
      "In the stillness of the morning light\n",
      "As the mist begins to lift\n",
      "Catching sight of a majestic scene\n",
      "An arafed mountain in the distance\n",
      "With a shimmering lake below\n",
      "Surrounded by trees ablaze with red\n",
      "This wondrous view takes my breath away\n",
      "Chorus 1:\n",
      "Oh, the beauty of this place\n",
      "Fills my heart with such delight\n",
      "The mountains rise so tall and proud\n",
      "While the lake reflects the colors bright\n",
      "\n",
      "Verse 1:\n",
      "Walking through the forest floor\n",
      "Leaves crunch beneath my feet\n",
      "Sunlight filters through the branches\n",
      "Creating patterns on the ground\n",
      "Each step brings me closer\n",
      "To the tranquil waterside\n",
      "My spirit lifts as nature surrounds\n",
      "\n",
      "Chorus 2:\n",
      "Oh, the peacefulness of this land\n",
      "Calms my soul and frees my mind\n",
      "The mountains tower above us all\n",
      "While the lake invites us to unwind\n",
      "\n",
      "Verse 2:\n",
      "Standing here beside the water\n",
      "Watching ripples dance and play\n",
      "Autumn's hues paint every leaf\n",
      "In vibrant shades of orange and gray\n",
      "The air grows crisp and cooler now\n",
      "As autumn's graceful dance comes near\n",
      "Yet, this moment feels eternal here\n",
      "\n",
      "Chorus 3:\n",
      "Oh, the splendor of this scene\n",
      "Captivates my senses fully\n",
      "The mountains loom so grand and strong\n",
      "While the lake whispers softly\n",
      "\n",
      "Bridge:\n",
      "Here, amidst this natural symphony\n",
      "I find solace in my soul\n",
      "For in this place, I am but small\n",
      "Compared to nature's endless whole\n",
      "\n",
      "Outro:\n",
      "May I forever cherish this serene retreat\n",
      "And carry its essence deep within my heart\n",
      "May I return often to this sacred space\n",
      "And continue to discover its healing art.\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot: Hola! Por favor inserte el nombre de la imagen que quieras usar para escribir una canción. Las imágenes se encuentran dentro de la carpeta /docs/\")\n",
    "#user_input = \"\"\n",
    "user_input = input(\"You: \")\n",
    "\n",
    "cap = generate_caption(user_input)\n",
    "\n",
    "response = generate_response(db, f\"Write a song lyrics about \\\"{cap}\\\" having intro, verse 1, chorus 1, verse 2, chorus 2, bridge, chorus 3, outro.\")\n",
    "postprocess_response(response)\n",
    "print(f\"Chatbot: {(response)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-lyrics-fA5n5Nhs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
